# Riducibilità polinomiale
## Relazioni interessanti, ma..
La maggior parte delle relazioni fra classi complessità che abbiamo visto, fino ad ora, sono **inclusioni improprie** (a parte $P\subset EXPTIME$  e $PSPACE = NPSPACE$).
Ossia, a parte queste due ultime relazioni, per ciascuna delle rimanenti relazioni non siamo in grado di dimostrare né l’inclusione propria né la coincidenza delle due classi che la costituiscono. 
Ad esempio, sappiamo che: 
1. Tutti i linguaggi che sono in $PSPACE$ sono anche in $EXPTIME$  ($PSPACE\subseteq EXPTIME$);
2. Tutti i linguaggi che sono in $P$ sono anche in $NP$  ($P\subseteq NP$)
Ma non sappiamo rispondere alle seguenti domande:
1. non sarà forse che tutti i linguaggi in $EXPTIME$ sono anche in $PSPACE$? Ossia, che $PSPACE = EXPTIME$?
2. Oppure, esiste almeno un linguaggio in $NP$ che non può essere deciso in tempo deterministico polinomiale? Ossia: è $P\subset NP$ oppure $P = NP$ ?
Le relazioni che conosciamo sono, in massima parte, relazioni *deboli*.
E, inoltre, pur riuscendo a dimostrare che una certa classe di complessità  è contenuta propriamente in un’altra classe di complessità $\mathcal C_2$ (ossia, $\mathcal C_1\subset\mathcal C_2$  ).
Anche in questo caso, seppure dimostriamo che un certo linguaggio $L$ appartiene a $\mathcal C_2$, come facciamo a sapere se quel linguaggio è anche in $\mathcal C_1$ oppure se, invece, è un *linguaggio separatore* fra $\mathcal C_1$ e $\mathcal C_2$ , ossia è contenuto in $\mathcal C_2-\mathcal C_1$ ?
Certo sarebbe utile se disponessimo di uno strumento che permettesse di individuare i linguaggi separatori fra due classi di complessità...
## $=$ oppure $\not =$ ?
Date due classi di complessità $C_1$ e $C_2$ tali che $C_1\subseteq C_2$, come fare per poter capire se $C1  = C2$  oppure $C1\not = C2$ ?
*Idea*: **se per caso trovassimo un linguaggio  $L_0\in C_2$ tale che**:  
1. **Supponendo di avere un algoritmo $\mathcal A$ che decide $L_0$ utilizzando una quantità di risorse pari a quella che definisce la classe $C_1$**;
2. **Per ogni altro linguaggio $L$ in $C_2$ riusciamo a costruire, simulando $\mathcal A$ , un algoritmo $\mathcal B_L$ che decide $L$ e che utilizza una quantità di risorse pari a quella che definisce la classe $C_1$**.
Allora, *se riuscissimo davvero a progettare $\mathcal A$ (dimostrando così che $L_0\in C_1$ ), sapremmo automaticamente che tutti i linguaggi in $C_2$ sono anche in $C_1$*. 
E, d’altra parte, questo implicherebbe anche che **se qualcuno riuscisse a dimostrare che $C1\not = C2$** allora **sapremmo automaticamente che  $L_0\not\in C_1$  sarebbe il padre di tutti i linguaggi in $C_2$** (il linguaggio più difficile fra tutti i linguaggi che stanno in $C_2$).
Bel ragionamento! Ma come facciamo a trovare il padre di tutti i linguaggi di una classe? 
## Una vecchia conoscenza
>[!info]- Ve le ricordate le care, vecchie, riduzioni? (paragrafo 5.5)

Dati due linguaggi, $L_1\subseteq\Sigma_1^*$  e $L_2\subseteq\Sigma_2^*$,  diciamo che $L_1$ **è riducibile a $L_2$  				e scriviamo $L1\succeq L2$** se:
Esiste una funzione $f:\Sigma_1^*\rightarrow\Sigma_2^*$ tale che:
1) $f$ è totale e calcolabile – ossia, è definita per ogni parola $x\in\Sigma_1^*$ e, inoltre, 
esiste una macchina di Turing di tipo trasduttore $T_f$ tale che, per ogni parola $x\in\Sigma_1^*$, la computazione $T_f(x)$ termina con la parola $f(x)\in\Sigma_2^*$ scritta sul nastro di output;
2) per ogni $x\in\Sigma_1^*$ vale che: $x\in L_1$  se e solo se $f(x)\in L_2$
$$\forall x\in\Sigma_1^*[x\in L_1\iff f(x)\in L2]$$
Ora, aggiungiamo una piccola richiesta alla funzione di riduzione $f$: richiediamo che, oltre ad essere totale e calcolabile
3) per ogni $x\in\Sigma_1^*$, $f(x)$ è calcolabile in tempo polinomiale in $|x|$ – ossia, $f\in FP$.
## Un nuovo strumento
Dati due linguaggi, $L_1\in\Sigma_1^*$  e $L_2\in\Sigma_2^*$,  diciamo che **$L_1$  è polinomialmente *riducibile* a $L_2$**  e scriviamo $L1\succeq_p L_2$  se:
Esiste una funzione $f:\Sigma_1^*\rightarrow\Sigma_2^*$ tale che
1) f è totale e calcolabile in tempo polinomiale (in breve, $f\in FP$) – ossia, è definita per ogni parola $x\in\Sigma_1^*$ e, inoltre, esiste una macchina di Turing di tipo trasduttore $T_f$ tale che, per ogni parola $x\in\Sigma_1^*$, la computazione $T_f(x)$ termina con la parola $f(x)\in\Sigma_2^*$ scritta sul nastro di output, ed esiste una costante $c$ tale che: per ogni $x\in\Sigma_1^*$ , $dtime(T_f,x)\in O(|x|^c )$;
2) per ogni $x\in\Sigma_1^*$ vale che: $x\in L_1$  se e solo se $f(x)\in L_2$
$$\forall x\in\Sigma_1^*[x\in L_1\iff f(x)\in L2]$$
La riducibilità polinomiale ci aiuterà a trovare il padre di tutti i problemi di una classe
>[!info]- E siamo al paragrafo 6.8: come sulla dispensa, d’ora in poi scriveremo sempre invece di p

Abbiamo due linguaggi, $L_1\in\Sigma_1^*$  e $L_2\in\Sigma_2^*$, e riusciamo a dimostrare che $L_1\succeq_p L_2$  (anzi, come abbiamo detto, leviamo la p: $L1\succeq L2$ ), cioè, dimostriamo che esistono un trasduttore $T_r$ e una costante $c$ tali che, per ogni $x\in\Sigma_1^*$, e, inoltre, per ogni $x\in\Sigma_1^*$, $dtime(T_r , x)\in O(|x|^c )$.

Supponiamo di sapere che $L2\in DTIME[f(n)]$, cioè, esiste un riconoscitore $T_2$ tale che, per ogni $y\in\Sigma_2^*$, $T_2(y)$ accetta se e soltanto se $y\in L_2$  e, inoltre, per ogni $y\in\Sigma_2^*$, $dtime(T_2, y)\in O( f (|y|) )$.  
Allora, possiamo costruire la seguente macchina $T_1$ : con input $x\in\Sigma_1^*$, $T_1$ opera in due fasi (ed utilizza due nastri):
**FASE 1**: $T_1$ simula $T_r(x)$ scrivendo l’output $y$ sul secondo nastro;
**FASE 2**: $T_1$ simula $T_2(y)$ sul secondo nastro: se $T_2(y)$ accetta allora anche $T_1$ accetta, se $T_2(y)$ rigetta allora anche $T_1$ rigetta. 
*$T_1$ decide $L_1$*: perché $T_2(y)$ accetta se e solo se $y\in L_2$ , e $y\in L_2$ se e solo se $x\in L_1$. 
Ma quanto impiega $T_1$ a decidere $L_1$?
Con input x:
1. La FASE 1 termina in $O(|x|^c )$ passi;
2. La FASE 2 termina in $O( f(|y|) )$ passi.
*Ma quanto è grande $|y|$ in funzione di $|x|$?*
Poiché $T_r(x)$ impiega $O(|x|^c )$ passi per calcolare $y$, e in questo numero di passi sono conteggiati anche i passi che occorrono a scrivere $y$ sul nastro di output, allora, $|y|\in O(|x|^c )$.
E, quindi, per ogni $x\in\Sigma_1^*$, $T_1(x)$ termina in $O(|x|^c + f(|x|^c ))$ passi.
Ossia, $L_1\in DTIME[ n^c + f( n^c ) ]$.

Allora, se $L_2\in P$ allora $L_1\in  P$. 
In questo caso, esiste una costante $k$ tale che  $L_2\in DTIME[ n^k  ]$. Allora, $L_1\in DTIME[ n^c + ( n^c )^k ]\subseteq P$.
Se $L_2\in EXPTIME$ allora $L_1\in EXPTIME$, 
Ma si può dimostrare la stessa cosa con le classi non deterministiche:
1. Se $L_2\in NP$ allora $L_1\in NP$; 
2. Se $L_2\in NEXPTIME$ allora $L_1\in NEXPTIME$.
E anche per le classi spaziali, se $L_2\in PSPACE$ allora $L_1\in PSPACE$. 
>[!info]- Il **Teorema 6.21** della dispensa 6 dimostra il solo caso “Se $L1\succeq L2$ e $L_2\in P$ allora $L_1\in  P$”, che è quel che abbiamo appena dimostrato!

## Lezione 13 vs Dispensa 6
